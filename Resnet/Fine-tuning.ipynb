{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JFF8zNkaPIwo"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/master_thesis/Resnet\n","!pip install carbontracker"]},{"cell_type":"code","source":["import os\n","import sys\n","import json\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","from tqdm import tqdm\n","\n","from model import resnet34\n","from carbontracker.tracker import CarbonTracker"],"metadata":{"id":"hl-qEpqj3HLP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ef5qH8uyjAis"},"outputs":[],"source":["def evaluate_model_on_testset(model, device, test_path):\n","    # Assume the test data is structured in a similar way to the training data\n","    test_transform = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","    test_dataset = datasets.ImageFolder(root=test_path, transform=test_transform)\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n","\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    test_loss = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    print(f'Accuracy on the test set: {accuracy:.2f}%')\n","\n","\n","\n","\n","def exponential_moving_average(data, alpha):\n","    \"\"\"Calculate the exponential moving average using the specified alpha value.\"\"\"\n","    return pd.Series(data).ewm(alpha=alpha, adjust=False).mean().values\n","\n","def plot_and_save_training_results(train_loss_values, val_loss_values, train_accuracy_values, val_accuracy_values, save_path, filename):\n","    if len(train_loss_values) == 0 or len(val_loss_values) == 0:\n","        print(\"No data to plot.\")\n","        return\n","\n","    # Calculate smoothed data\n","    smoothed_train_loss = exponential_moving_average(train_loss_values, 0.5)\n","    smoothed_val_loss = exponential_moving_average(val_loss_values, 0.5)\n","    smoothed_train_accuracy = exponential_moving_average(train_accuracy_values, 0.5)\n","    smoothed_val_accuracy = exponential_moving_average(val_accuracy_values, 0.5)\n","\n","    epochs_range = range(1, len(train_loss_values) + 1)\n","    plt.figure(figsize=(12, 6))\n","\n","    # Plot training and validation loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs_range, smoothed_train_loss, label='Training Loss', color='blue')\n","    plt.plot(epochs_range, smoothed_val_loss, label='Validation Loss', color='red')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title('Training and Validation Loss')\n","    plt.legend()\n","\n","    # Plot training and validation accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs_range, smoothed_train_accuracy, label='Training Accuracy', color='blue')\n","    plt.plot(epochs_range, smoothed_val_accuracy, label='Validation Accuracy', color='red')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.title('Training and Validation Accuracy')\n","    plt.legend()\n","    plt.ylim([0, 1])\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(save_path, filename))\n","    plt.show()\n","\n","\n","def count_parameters(model, trainable_only=True):\n","    \"\"\"Calculate the total number of parameters in the model. If trainable_only is True, only count the trainable parameters.\"\"\"\n","    if trainable_only:\n","        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    else:\n","        return sum(p.numel() for p in model.parameters())\n"]},{"cell_type":"code","source":["class NewFC(nn.Module):\n","    def __init__(self, in_features):\n","        super(NewFC, self).__init__()\n","        self.flatten = nn.Flatten()  # Flatten layer\n","        self.fc1 = nn.Linear(in_features, 512)  # Fully connected layer from in_features to 512 features\n","        self.relu = nn.ReLU()  # Activation function\n","        self.dropout = nn.Dropout(0.5)  # Dropout with a rate of 50%\n","        self.fc2 = nn.Linear(512, 2)  # Final layer mapping to 2 classes\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n"],"metadata":{"id":"CLfjD9DWDis5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"using {} device.\".format(device))\n","\n","    data_transform = {\n","        \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n","                                     transforms.RandomHorizontalFlip(),\n","                                     transforms.ToTensor(),\n","                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n","        \"val\": transforms.Compose([transforms.Resize(256),\n","                                   transforms.CenterCrop(224),\n","                                   transforms.ToTensor(),\n","                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n","\n","    # Change the path to the desired dataset\n","    image_path = \"/content/drive/MyDrive/master_thesis/Datasets/BreastMNIST\"\n","    # image_path = \"/content/drive/MyDrive/master_thesis/Datasets/Herlev\"\n","    # image_path = \"/content/drive/MyDrive/master_thesis/Datasets/ISIC\"\n","    assert os.path.exists(image_path), \"{} path does not exist.\".format(image_path)\n","\n","    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"train\"),\n","                                         transform=data_transform[\"train\"])\n","    train_num = len(train_dataset)\n","\n","    # Save class-to-index mapping\n","    class_dict = train_dataset.class_to_idx\n","    class_dict_rev = dict((val, key) for key, val in class_dict.items())\n","    json_str = json.dumps(class_dict_rev, indent=4)\n","    with open('class_indices.json', 'w') as json_file:\n","        json_file.write(json_str)\n","\n","    batch_size = 16\n","    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n","    print('Using {} dataloader workers every process'.format(nw))\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                               batch_size=batch_size, shuffle=True,\n","                                               num_workers=nw)\n","\n","    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, \"val\"),\n","                                            transform=data_transform[\"val\"])\n","    val_num = len(validate_dataset)\n","    validate_loader = torch.utils.data.DataLoader(validate_dataset,\n","                                                  batch_size=batch_size, shuffle=False,\n","                                                  num_workers=nw)\n","\n","    print(\"using {} images for training, {} images for validation.\".format(train_num, val_num))\n","\n","    net = resnet34()\n","\n","    # Transfer Learning: Load pre-trained weights\n","    model_weight_path = \"./resnet34-pre.pth\"\n","    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n","    net.load_state_dict(torch.load(model_weight_path, map_location='cpu', weights_only=True))\n","\n","    ######\n","    # Structure A: Basic ResNet34 with modified output layer (choose one structure at a time)\n","    in_channel = net.fc.in_features\n","    net.fc = nn.Linear(in_channel, 2)  # Output layer changed to classify 2 classes\n","    net.to(device)\n","\n","    ######\n","    # Structure B: Add a new fully connected layer without replacing the existing one\n","    # Uncomment the following block if you want to test Structure B:\n","    # in_features = net.fc.in_features\n","    # net.fc = nn.Sequential(\n","    #     nn.Linear(in_features, 1000),  # Original fully connected layer\n","    #     nn.ReLU(),\n","    #     nn.Linear(1000, 2)  # New layer from 1000 classes to 2 classes\n","    # )\n","    # net.to(device)\n","\n","    ######\n","    # Structure C: Replace the original fully connected layer with a new one\n","    # Uncomment the following block if you want to test Structure C:\n","    # in_features = net.fc.in_features\n","    # net.fc = NewFC(in_features)  # Replace with custom fully connected layer\n","    # net.to(device)\n","\n","    # Calculate and print model parameters\n","    total_params = count_parameters(net, trainable_only=False)\n","    trainable_params = count_parameters(net, trainable_only=True)\n","    print(f\"Total parameters: {total_params}\")\n","    print(f\"Trainable parameters: {trainable_params}\")\n","\n","    loss_function = nn.CrossEntropyLoss()\n","    params = [p for p in net.parameters() if p.requires_grad]\n","    optimizer = optim.Adam(params, lr=0.0001)\n","\n","    epochs = 200\n","    best_acc = 0.0\n","    save_path = './resnet34_fine_tuning_breastmnist_structureA.pth'  # Modify based on structure\n","    train_steps = len(train_loader)\n","\n","    tracker = CarbonTracker(epochs=epochs)\n","\n","    train_loss_values = []\n","    train_accuracy_values = []\n","    val_loss_values = []\n","    val_accuracy_values = []\n","\n","    for epoch in range(epochs):\n","        tracker.epoch_start()\n","\n","        net.train()\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","        train_bar = tqdm(train_loader, file=sys.stdout)\n","\n","        for step, data in enumerate(train_bar):\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = net(images)\n","            loss = loss_function(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","            train_bar.desc = \"train epoch[{}/{}] loss:{:.3f}\".format(epoch + 1, epochs, loss.item())\n","\n","        train_loss = running_loss / len(train_loader.dataset)\n","        train_accuracy = correct / total\n","        train_loss_values.append(train_loss)\n","        train_accuracy_values.append(train_accuracy)\n","\n","        net.eval()\n","        val_loss = 0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            val_bar = tqdm(validate_loader, file=sys.stdout)\n","            for val_data in val_bar:\n","                val_images, val_labels = val_data\n","                val_images, val_labels = val_images.to(device), val_labels.to(device)\n","                outputs = net(val_images)\n","                val_loss += loss_function(outputs, val_labels).item()\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += val_labels.size(0)\n","                correct += (predicted == val_labels).sum().item()\n","\n","        val_loss /= len(validate_loader.dataset)\n","        val_accuracy = correct / total\n","        val_loss_values.append(val_loss)\n","        val_accuracy_values.append(val_accuracy)\n","\n","        print('[epoch %d] train_loss: %.3f, train_accuracy: %.3f, val_loss: %.3f, val_accuracy: %.3f' %\n","              (epoch + 1, train_loss, train_accuracy, val_loss, val_accuracy))\n","\n","        if val_accuracy > best_acc:\n","            best_acc = val_accuracy\n","            torch.save(net.state_dict(), save_path)\n","\n","        tracker.epoch_end()\n","\n","    tracker.stop()\n","    print('Finished Training')\n","\n","    # Plot and save training results\n","    plot_and_save_training_results(\n","        train_loss_values,\n","        val_loss_values,\n","        train_accuracy_values,\n","        val_accuracy_values,\n","        \"/content/drive/MyDrive/master_thesis/Results\",\n","        \"fine_tuning_breastmnist_structureA.png\"\n","    )\n","\n","    # Test the model\n","    test_path = \"/content/drive/MyDrive/master_thesis/Datasets/BreastMNIST/test\"\n","    # test_path = \"/content/drive/MyDrive/master_thesis/Datasets/Herlev/test\"\n","    # test_path = \"/content/drive/MyDrive/master_thesis/Datasets/ISIC/test\"\n","    evaluate_model_on_testset(net, device, test_path)\n","\n","\n","if __name__ == '__main__':\n","    main()\n"],"metadata":{"id":"bEgeXUlaClvj"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyO7mcdJqNepocGa+pEohn53"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}